# âœ‹ğŸ¨ Air Canvas using Machine Learning

Welcome to **Air Canvas**, a computer vision-based virtual painting application that allows users to draw in the air using hand gestures. Powered by **MediaPipe** for hand tracking and **OpenCV** for image processing, this interactive project offers a touchless, intuitive digital drawing experience â€” perfect for education, entertainment, and creative prototyping.

---

## ğŸ“Œ Table of Contents

* [ğŸ“– Overview](#-overview)
* [ğŸ’¡ Features](#-features)
* [ğŸ§  How It Works](#-how-it-works)
* [ğŸ”§ Dependencies](#-dependencies)
* [ğŸ“ Project Structure](#-project-structure)
* [ğŸ–¼ï¸ User Interface Overview](#-user-interface-overview)
* [ğŸ–ï¸ Gesture Mechanics](#-gesture-mechanics)
* [ğŸ¯ Use Cases](#-use-cases)
* [âš ï¸ Limitations](#-limitations)
* [ğŸš€ Future Improvements](#-future-improvements)

---

## ğŸ“– Overview

**Air Canvas** is an AI-driven virtual canvas that enables users to draw on screen by waving their fingers in the air, without any physical contact or touch screen. This is achieved through real-time hand tracking and gesture recognition using **MediaPipe** â€” a powerful ML solution by Google.

The system detects the movement of your index finger and tracks it to draw colored strokes on a canvas. You can also change colors or clear the canvas using gesture-based buttons displayed at the top of the screen.

This project is especially useful in the domains of **gesture-based HCI (Human-Computer Interaction)**, **AI-enabled art tools**, and **contactless design interfaces**.

---

## ğŸ’¡ Features

* ğŸ‘† **Finger-based Air Drawing**
  Uses your index finger as a pen to draw freely in the air.

* ğŸ¨ **Color Selection Panel**
  Switch between multiple colors using virtual buttons on-screen.

* âŒ **Clear Canvas Button**
  A touchless "CLEAR" option to erase all drawings with a single gesture.

* ğŸ¤ **Gesture-based Stroke Separation**
  Pinch gesture (thumb + index finger) is recognized as "pen lift" to start a new stroke.

* ğŸ§  **Real-time Hand Tracking**
  Uses MediaPipeâ€™s ML-based hand detection for accurate tracking.

* ğŸ“· **Live Camera Feed Overlay**
  The user sees both the canvas and their live feed with drawn landmarks.

---

## ğŸ§  How It Works

### ğŸ” 1. **Hand Detection and Landmark Recognition**

The system uses **MediaPipe Hands**, which detects and tracks 21 hand landmarks in real-time. Once a hand is detected, the coordinates of the **index finger tip** and **thumb tip** are extracted.

### ğŸ¯ 2. **Gesture Interpretation**

* **Index Finger Tip Movement** â†’ used to paint.
* **Index & Thumb Proximity** â†’ interpreted as "pen lift".
* **Finger at Top Edge** â†’ interpreted as interaction with color selection buttons.

### ğŸ–¼ï¸ 3. **Drawing Mechanism**

A `deque` (double-ended queue) buffer stores the coordinates of the drawing strokes, and lines are drawn between consecutive points. Separate buffers are maintained for each color to manage undo-like behavior without merging all data.

### ğŸ§° 4. **UI Elements**

Color and CLEAR buttons are drawn at the top of the screen and replicated both on the live feed and the actual drawing canvas (`paintWindow`). These virtual buttons respond to the X-Y position of the index finger if it hovers over them.

---

## ğŸ”§ Dependencies

This project requires the following Python libraries:

* **OpenCV (cv2)** â€“ For image processing and GUI
* **MediaPipe** â€“ For hand tracking and landmark recognition
* **NumPy** â€“ For matrix and image data handling
* **collections.deque** â€“ Efficient drawing history management

Installation can be done using:

```bash
pip install opencv-python mediapipe numpy
```

---

## ğŸ“ Project Structure

```
air-canvas/
â”‚
â”œâ”€â”€ air_canvas.py         # Main script with drawing logic and MediaPipe hand tracking
â”œâ”€â”€ README.md             # Project documentation
â””â”€â”€ requirements.txt      # Dependency list
```

---

## ğŸ–¼ï¸ User Interface Overview

The UI is divided into two main components:

### ğŸ¥ 1. **Live Video Feed ("Output")**

* Shows the userâ€™s webcam feed.
* Hand landmarks and drawing strokes are overlaid.
* Button panel appears at the top (CLEAR, BLUE, GREEN, RED, YELLOW).

### ğŸ–Œï¸ 2. **Paint Window**

* A separate window that displays the strokes without the webcam feed.
* Ideal for saving as an artwork or exporting.

---

## ğŸ–ï¸ Gesture Mechanics

| Gesture               | Action                      |
| --------------------- | --------------------------- |
| Index Finger Movement | Draw on canvas              |
| Index + Thumb Pinch   | Lift pen (start new stroke) |
| Index at Top Buttons  | Select color / clear canvas |
| 'Q' Key Press         | Exit the application        |

---

## ğŸ¯ Use Cases

* **Educational Tools**: Teaching drawing, handwriting, or STEM without whiteboards or physical markers.
* **Gesture-based Interfaces**: Prototyping HCI systems that rely on touchless controls.
* **Creative Expression**: Artists can draw or doodle using only hand gestures.
* **Therapy & Accessibility**: Alternative input methods for users with physical limitations.

---

## âš ï¸ Limitations

* **Lighting Dependency**: Poor lighting may affect hand detection accuracy.
* **Single-Hand Operation**: Currently supports only one hand for interaction.
* **Lack of Undo Feature**: No built-in undo; you can only clear or continue drawing.
* **No Saving Option**: Canvas output must be saved manually (via screenshot or code extension).

---

## ğŸš€ Future Improvements

* âœ… Add multi-hand support for dual tool interaction.
* ğŸ’¾ Implement image saving and loading features.
* ğŸ”„ Add undo/redo buffer for better control.
* âœ¨ Improve gesture variety (e.g., two-finger zoom, erase).
* ğŸ“± Port to mobile devices or integrate with AR frameworks.

---
